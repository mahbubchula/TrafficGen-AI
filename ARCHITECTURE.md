# ðŸ—ï¸ TrafficGen-AI Ultimate Edition - System Architecture Documentation

**Version:** 2.0  
**Last Updated:** December 28, 2025  
**Author:** Mahbub Hassan, Chulalongkorn University

---

## ðŸ“‹ Table of Contents

1. [Overview](#1-overview)
2. [System Architecture](#2-system-architecture)
3. [Component Details](#3-component-details)
4. [Data Flow](#4-data-flow)
5. [Module Specifications](#5-module-specifications)
6. [API Integration](#6-api-integration)
7. [Algorithm Implementations](#7-algorithm-implementations)
8. [Database Schema](#8-database-schema)
9. [Security & Privacy](#9-security--privacy)
10. [Performance Optimization](#10-performance-optimization)
11. [Deployment Architecture](#11-deployment-architecture)
12. [Future Extensions](#12-future-extensions)

---

## 1. Overview

### 1.1 System Purpose

TrafficGen-AI Ultimate Edition is a research-grade platform designed to:
- Generate climate-adaptive traffic policies using Large Language Models
- Simulate traffic scenarios under various climate stress conditions
- Evaluate policy performance using multiple metrics
- Perform multi-objective optimization and statistical analysis
- Generate publication-ready reports and visualizations

### 1.2 Technology Stack

| Layer | Technology | Version | Purpose |
|-------|------------|---------|---------|
| **Frontend** | Streamlit | 1.31.0 | Web-based user interface |
| **Backend** | Python | 3.8+ | Core logic and processing |
| **AI/ML** | Groq API (Llama 3.3 70B) | Latest | Policy generation & interpretation |
| **Simulation** | SUMO + TraCI | 1.19.0 | Traffic microsimulation |
| **Visualization** | Plotly | 5.18.0 | Interactive charts |
| **Data Processing** | Pandas + NumPy | 2.1.4 / 1.26.3 | Data manipulation |
| **Statistical Analysis** | SciPy | Latest | Statistical testing |
| **Environment Management** | python-dotenv | 1.0.0 | Configuration management |

### 1.3 Design Principles

1. **Modularity**: Each component is independent and reusable
2. **Scalability**: Architecture supports expansion to larger datasets
3. **Maintainability**: Clear separation of concerns
4. **Reproducibility**: All analyses are deterministic and traceable
5. **Extensibility**: Easy to add new features and modules
6. **User-Centric**: Intuitive interface for non-technical users

---

## 2. System Architecture

### 2.1 High-Level Architecture Diagram
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     USER INTERFACE LAYER                         â”‚
â”‚                     (Streamlit Frontend)                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚   Home   â”‚ Policy   â”‚Simulationâ”‚ Results  â”‚ Advanced â”‚      â”‚
â”‚  â”‚   Page   â”‚   Gen    â”‚   & Eval â”‚ Analysis â”‚ Features â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   APPLICATION CONTROLLER                         â”‚
â”‚                         (app.py)                                 â”‚
â”‚  â€¢ Session Management                                            â”‚
â”‚  â€¢ Page Routing                                                  â”‚
â”‚  â€¢ State Management                                              â”‚
â”‚  â€¢ Theme Management                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼                     â–¼                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   BUSINESS    â”‚    â”‚   AI/ML        â”‚    â”‚  ANALYTICS   â”‚
â”‚   LOGIC       â”‚    â”‚   SERVICES     â”‚    â”‚  SERVICES    â”‚
â”‚   LAYER       â”‚    â”‚   LAYER        â”‚    â”‚  LAYER       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                     â”‚                     â”‚
        â–¼                     â–¼                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     CORE MODULES                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Policy   â”‚ Climate  â”‚   SUMO   â”‚Evaluator â”‚Optimizerâ”‚ â”‚
â”‚  â”‚Generator â”‚Scenarios â”‚Simulator â”‚          â”‚         â”‚ â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
â”‚  â”‚Interpreterâ”‚Analyticsâ”‚  Report  â”‚Advanced  â”‚         â”‚ â”‚
â”‚  â”‚          â”‚         â”‚ Generator â”‚   Viz    â”‚         â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼                     â–¼                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  EXTERNAL     â”‚    â”‚ CONFIGURATION  â”‚    â”‚    DATA      â”‚
â”‚  SERVICES     â”‚    â”‚    LAYER       â”‚    â”‚   STORAGE    â”‚
â”‚               â”‚    â”‚                â”‚    â”‚              â”‚
â”‚ â€¢ Groq API    â”‚    â”‚ â€¢ Settings     â”‚    â”‚ â€¢ Session    â”‚
â”‚ â€¢ SUMO Engine â”‚    â”‚ â€¢ Prompts      â”‚    â”‚   State      â”‚
â”‚               â”‚    â”‚ â€¢ Themes       â”‚    â”‚ â€¢ Cache      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 Component Interaction Flow
```
User Action
    â”‚
    â–¼
[Streamlit UI] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                                                 â”‚
    â”‚ User Input                                      â”‚
    â–¼                                                 â”‚
[Session State Management]                           â”‚
    â”‚                                                 â”‚
    â”‚ Process Request                                â”‚
    â–¼                                                 â”‚
[Application Controller]                             â”‚
    â”‚                                                 â”‚
    â”œâ”€â–º [Policy Generator] â”€â”€â–º [Groq API]           â”‚
    â”‚        â”‚                      â”‚                â”‚
    â”‚        â”‚                      â–¼                â”‚
    â”‚        â”‚              [LLM Response]           â”‚
    â”‚        â”‚                      â”‚                â”‚
    â”‚        â–¼                      â”‚                â”‚
    â”‚   [Validation] â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
    â”‚        â”‚                                       â”‚
    â”‚        â–¼                                       â”‚
    â”œâ”€â–º [SUMO Simulator] â”€â”€â–º [Traffic Simulation]   â”‚
    â”‚        â”‚                                       â”‚
    â”‚        â–¼                                       â”‚
    â”œâ”€â–º [Performance Evaluator] â”€â”€â–º [Metrics]       â”‚
    â”‚        â”‚                                       â”‚
    â”‚        â–¼                                       â”‚
    â”œâ”€â–º [Multi-Objective Optimizer] â”€â”€â–º [Pareto]    â”‚
    â”‚        â”‚                                       â”‚
    â”‚        â–¼                                       â”‚
    â”œâ”€â–º [Statistical Analyzer] â”€â”€â–º [ANOVA/CI]       â”‚
    â”‚        â”‚                                       â”‚
    â”‚        â–¼                                       â”‚
    â”œâ”€â–º [Advanced Visualizer] â”€â”€â–º [Charts]          â”‚
    â”‚        â”‚                                       â”‚
    â”‚        â–¼                                       â”‚
    â””â”€â–º [Report Generator] â”€â”€â–º [Documents]          â”‚
             â”‚                                       â”‚
             â–¼                                       â”‚
    [Results Display] â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
    [User Feedback]
```

---

## 3. Component Details

### 3.1 Frontend Layer (Streamlit)

**Location:** `app.py`

**Responsibilities:**
- User interface rendering
- User input collection
- Result visualization
- Navigation management
- Theme switching
- Session state management

**Key Features:**
- **9 Main Pages:**
  1. Home - Overview and quick stats
  2. Policy Generation - AI-powered policy creation
  3. Simulation & Evaluation - Traffic simulation execution
  4. Results Analysis - Performance comparison
  5. Multi-Objective Optimization - Pareto analysis
  6. Statistical Analysis - Hypothesis testing
  7. Advanced Visualizations - Premium charts
  8. Report Generation - Automated documentation
  9. About - System information

**State Management:**
```python
st.session_state = {
    'generated_policies': [],        # List of generated policies
    'simulation_results': {},        # Simulation output data
    'api_key_set': False,           # API authentication status
    'theme': 'light',               # UI theme preference
    'pareto_front': [],             # Optimization results
    'statistical_analysis': {}       # Statistical test results
}
```

### 3.2 Application Controller

**Location:** `app.py` (main function)

**Responsibilities:**
- Route requests to appropriate handlers
- Initialize modules
- Manage workflow orchestration
- Error handling and logging
- Performance monitoring

**Routing Logic:**
```python
def main():
    apply_theme()  # Apply user-selected theme
    render_sidebar()  # Sidebar navigation
    
    if page == "Home":
        show_home_page()
    elif page == "Policy Generation":
        show_policy_generation_page(api_key)
    # ... additional routes
```

### 3.3 Configuration Layer

**Location:** `config/`

**Files:**
- `settings.py` - System configuration
- `prompts.py` - LLM prompt templates
- `__init__.py` - Module initialization

**Configuration Categories:**

1. **API Configuration**
```python
   GROQ_API_KEY = os.getenv("GROQ_API_KEY")
   GROQ_MODEL = "llama-3.3-70b-versatile"
```

2. **Simulation Parameters**
```python
   DEFAULT_SIMULATION_TIME = 3600  # seconds
   SIMULATION_STEP_SIZE = 1.0
   WARMUP_TIME = 300
```

3. **Climate Scenarios**
```python
   CLIMATE_SCENARIOS = {
       "baseline": {...},
       "moderate": {...},
       "severe": {...},
       "extreme": {...}
   }
```

4. **Theme Settings**
```python
   THEMES = {
       "light": {...},
       "dark": {...}
   }
```

---

## 4. Data Flow

### 4.1 Policy Generation Flow
```
User Input (Network Type, Climate, Objectives)
    â”‚
    â–¼
[Format Prompt Template]
    â”‚
    â–¼
[Send to Groq API]
    â”‚
    â”œâ”€â–º Model: llama-3.3-70b-versatile
    â”œâ”€â–º Temperature: 0.7
    â””â”€â–º Max Tokens: 2000
    â”‚
    â–¼
[Receive JSON Response]
    â”‚
    â”œâ”€â–º Remove markdown artifacts
    â”œâ”€â–º Parse JSON
    â””â”€â–º Validate structure
    â”‚
    â–¼
[Add Metadata]
    â”‚
    â”œâ”€â–º Timestamp
    â”œâ”€â–º Generation parameters
    â””â”€â–º Model version
    â”‚
    â–¼
[Store in Session State]
    â”‚
    â–¼
[Display to User]
```

### 4.2 Simulation Flow
```
Selected Policies + Scenarios
    â”‚
    â–¼
[Create Simulation Matrix]
    â”‚  Policy 1 Ã— Scenario A
    â”‚  Policy 1 Ã— Scenario B
    â”‚  Policy 2 Ã— Scenario A
    â”‚  ...
    â–¼
For each (Policy, Scenario) pair:
    â”‚
    â”œâ”€â–º [Apply Climate Parameters]
    â”‚      â”‚
    â”‚      â”œâ”€â–º Capacity reduction
    â”‚      â”œâ”€â–º Efficiency loss
    â”‚      â””â”€â–º Emission factor
    â”‚      â”‚
    â”œâ”€â–º [Apply Policy Configuration]
    â”‚      â”‚
    â”‚      â”œâ”€â–º Signal timing
    â”‚      â”œâ”€â–º Speed limits
    â”‚      â””â”€â–º Access rules
    â”‚      â”‚
    â”œâ”€â–º [Run SUMO Simulation]
    â”‚      â”‚
    â”‚      â”œâ”€â–º Generate traffic demand
    â”‚      â”œâ”€â–º Execute simulation
    â”‚      â””â”€â–º Collect vehicle data
    â”‚      â”‚
    â”œâ”€â–º [Calculate Metrics]
    â”‚      â”‚
    â”‚      â”œâ”€â–º Average delay
    â”‚      â”œâ”€â–º Throughput
    â”‚      â”œâ”€â–º Emissions
    â”‚      â”œâ”€â–º Speed
    â”‚      â””â”€â–º Travel time
    â”‚      â”‚
    â””â”€â–º [Store Results]
         â”‚
         â–¼
    results[policy][scenario] = {
        'metrics': {...},
        'policy_config': {...},
        'scenario': {...}
    }
    â”‚
    â–¼
[Aggregate Results]
    â”‚
    â–¼
[Display Summary]
```

### 4.3 Optimization Flow
```
Simulation Results
    â”‚
    â–¼
[Extract Metrics for Each Policy]
    â”‚
    â”œâ”€â–º Average across scenarios
    â””â”€â–º Create objective matrix
    â”‚
    â–¼
[Multi-Objective Analysis]
    â”‚
    â”œâ”€â–º [Calculate Pareto Frontier]
    â”‚      â”‚
    â”‚      â”œâ”€â–º For each policy:
    â”‚      â”‚   Check if dominated by others
    â”‚      â”‚
    â”‚      â””â”€â–º Non-dominated = Pareto optimal
    â”‚
    â”œâ”€â–º [Rank by Dominance]
    â”‚      â”‚
    â”‚      â””â”€â–º Count dominating solutions
    â”‚
    â”œâ”€â–º [Calculate Hypervolume]
    â”‚      â”‚
    â”‚      â””â”€â–º Measure solution quality
    â”‚
    â””â”€â–º [Generate Report]
         â”‚
         â–¼
    [Display Results + Visualizations]
```

### 4.4 Statistical Analysis Flow
```
Simulation Results
    â”‚
    â–¼
[Prepare Data Structures]
    â”‚
    â”œâ”€â–º Group by policy
    â”œâ”€â–º Group by scenario
    â””â”€â–º Group by metric
    â”‚
    â–¼
[ANOVA Testing]
    â”‚
    â”œâ”€â–º For each metric:
    â”‚   â”œâ”€â–º F-statistic
    â”‚   â”œâ”€â–º P-value
    â”‚   â””â”€â–º Significance test
    â”‚
    â–¼
[Confidence Intervals]
    â”‚
    â”œâ”€â–º For each (policy, metric):
    â”‚   â”œâ”€â–º Mean
    â”‚   â”œâ”€â–º Standard error
    â”‚   â”œâ”€â–º 95% CI bounds
    â”‚   â””â”€â–º Margin of error
    â”‚
    â–¼
[Correlation Analysis]
    â”‚
    â”œâ”€â–º Create correlation matrix
    â”œâ”€â–º Calculate Pearson r
    â””â”€â–º Identify strong correlations
    â”‚
    â–¼
[Generate Statistical Report]
    â”‚
    â–¼
[Display Results]
```

---

## 5. Module Specifications

### 5.1 Policy Generator Module

**File:** `modules/policy_generator.py`

**Class:** `PolicyGenerator`

**Purpose:** Generate traffic policy configurations using LLM

**Key Methods:**
```python
class PolicyGenerator:
    def __init__(self, api_key=None):
        """Initialize with Groq API client"""
        
    def generate_policy(self, network_type, climate_scenario, 
                       policy_objective, constraints) -> dict:
        """
        Generate single policy configuration
        
        Returns:
            {
                'policy_name': str,
                'policy_type': str,
                'description': str,
                'parameters': dict,
                'expected_impacts': dict,
                'implementation_notes': str,
                'generation_metadata': dict
            }
        """
        
    def generate_multiple_policies(self, network_type, 
                                   climate_scenario, 
                                   policy_objectives) -> list:
        """Generate multiple policies for different objectives"""
        
    def validate_policy(self, policy) -> tuple:
        """Validate policy structure (is_valid, error_message)"""
```

**Input Schema:**
```json
{
  "network_type": "Urban Arterial | Highway Corridor | City Grid | ...",
  "climate_scenario": "Baseline | Moderate | Severe | Extreme",
  "policy_objective": "Minimize Delay | Reduce Emissions | ...",
  "constraints": "Free text description"
}
```

**Output Schema:**
```json
{
  "policy_name": "string",
  "policy_type": "Signal Timing | Road Pricing | Access Restriction | ...",
  "description": "string",
  "parameters": {
    "param1": "value1",
    "param2": "value2"
  },
  "expected_impacts": {
    "delay": "string",
    "emissions": "string",
    "throughput": "string"
  },
  "implementation_notes": "string",
  "generation_metadata": {
    "network_type": "string",
    "climate_scenario": "string",
    "policy_objective": "string",
    "constraints": "string",
    "model_used": "string",
    "timestamp": "ISO datetime"
  }
}
```

**API Integration:**
```python
response = groq_client.chat.completions.create(
    model="llama-3.3-70b-versatile",
    messages=[
        {"role": "system", "content": "Traffic engineering expert"},
        {"role": "user", "content": formatted_prompt}
    ],
    temperature=0.7,
    max_tokens=2000
)
```

### 5.2 Climate Scenarios Module

**File:** `modules/climate_scenarios.py`

**Class:** `ClimateScenarioManager`

**Purpose:** Manage climate stress scenario definitions and applications

**Key Methods:**
```python
class ClimateScenarioManager:
    def get_scenario(self, scenario_name) -> dict:
        """Get scenario configuration"""
        
    def apply_capacity_reduction(self, base_capacity, scenario_name) -> float:
        """Apply capacity reduction factor"""
        
    def apply_efficiency_loss(self, base_speed, scenario_name) -> float:
        """Apply efficiency loss to speeds"""
        
    def get_emission_factor(self, scenario_name) -> float:
        """Get emission multiplication factor"""
        
    def get_scenario_summary(self, scenario_name) -> str:
        """Get human-readable scenario description"""
        
    def compare_scenarios(self, base_value, metric_name) -> dict:
        """Compare impact across all scenarios"""
```

**Scenario Data Structure:**
```python
{
    "baseline": {
        "name": "Baseline (No Climate Stress)",
        "capacity_reduction": 0.0,    # 0% reduction
        "efficiency_loss": 0.0,       # 0% loss
        "emission_factor": 1.0        # No increase
    },
    "moderate": {
        "name": "Moderate Climate Stress",
        "capacity_reduction": 0.15,   # 15% reduction
        "efficiency_loss": 0.10,      # 10% loss
        "emission_factor": 1.15       # 15% increase
    },
    # ... severe, extreme
}
```

### 5.3 SUMO Simulator Module

**File:** `modules/sumo_simulator.py`

**Class:** `SUMOSimulator`

**Purpose:** Interface with SUMO traffic microsimulation engine

**Key Methods:**
```python
class SUMOSimulator:
    def __init__(self, network_dir="sumo_networks"):
        """Initialize simulator"""
        
    def create_simple_network(self, network_name) -> str:
        """Create synthetic network for testing"""
        
    def generate_traffic_demand(self, network_path, 
                                num_vehicles, 
                                demand_pattern) -> str:
        """Generate route file with traffic demand"""
        
    def run_simulation(self, config_file, policy_config, 
                      climate_scenario, simulation_time) -> dict:
        """Execute simulation and return results"""
        
    def apply_policy_to_network(self, policy_config, network_path):
        """Modify network based on policy"""
```

**Simulation Output Structure:**
```python
{
    'simulation_time': int,           # Duration in seconds
    'vehicles': [                     # List of vehicle data
        {
            'id': str,
            'delay': float,           # seconds
            'speed': float,           # m/s
            'travel_time': float,     # seconds
            'distance': float,        # meters
            'co2_emissions': float,   # grams
            'completed': bool
        },
        # ...
    ],
    'policy_applied': str,            # Policy name
    'climate_scenario': str           # Scenario name
}
```

**Current Implementation:**
- Uses **synthetic data generation** for demonstration
- In production, would integrate with actual SUMO via TraCI API
- Supports parameterized climate stress application

### 5.4 Performance Evaluator Module

**File:** `modules/evaluator.py`

**Class:** `PerformanceEvaluator`

**Purpose:** Calculate and analyze traffic performance metrics

**Key Methods:**
```python
class PerformanceEvaluator:
    def calculate_metrics(self, simulation_data) -> dict:
        """
        Calculate performance metrics from simulation
        
        Returns:
            {
                'average_delay': float,
                'throughput': float,
                'co2_emissions': float,
                'average_speed': float,
                'total_travel_time': float
            }
        """
        
    def compare_policies(self, baseline_metrics, policy_metrics) -> dict:
        """Compare policy vs baseline"""
        
    def calculate_composite_score(self, metrics, weights=None) -> float:
        """Calculate weighted aggregate score (0-100)"""
        
    def generate_summary_table(self, results_dict) -> pd.DataFrame:
        """Create formatted summary table"""
        
    def identify_best_policy(self, results_dict, objective) -> str:
        """Identify best performing policy"""
```

**Metrics Calculation:**

1. **Average Delay:**
```python
   average_delay = mean(vehicle['delay'] for all vehicles)
```

2. **Throughput:**
```python
   throughput = (completed_vehicles / simulation_time) * 3600  # veh/hour
```

3. **COâ‚‚ Emissions:**
```python
   co2_emissions = sum(vehicle['co2_emissions']) / 1000  # kg
```

4. **Average Speed:**
```python
   average_speed = mean(vehicle['speed']) * 3.6  # km/h
```

5. **Composite Score:**
```python
   # Normalize each metric to 0-100 scale
   normalized_delay = (300 - delay) / 300 * 100
   normalized_throughput = throughput / 2000 * 100
   normalized_emissions = (1000 - emissions) / 1000 * 100
   normalized_speed = speed / 60 * 100
   
   # Weighted sum
   score = sum(normalized[i] * weight[i])
```

### 5.5 Result Interpreter Module

**File:** `modules/interpreter.py`

**Class:** `ResultInterpreter`

**Purpose:** Generate natural language interpretations using LLM

**Key Methods:**
```python
class ResultInterpreter:
    def interpret_results(self, policy_config, metrics, 
                         climate_scenario, baseline_metrics=None) -> str:
        """Generate interpretation of single policy results"""
        
    def compare_multiple_policies(self, policies_results, 
                                  climate_scenarios) -> str:
        """Generate comparative analysis of multiple policies"""
        
    def generate_executive_summary(self, best_policy, 
                                   key_findings, recommendations) -> str:
        """Generate executive summary"""
```

**Interpretation Process:**
```
Metrics + Policy Config
    â”‚
    â–¼
[Format Results Summary]
    â”‚
    â”œâ”€â–º Performance metrics table
    â”œâ”€â–º Comparison to baseline
    â””â”€â–º Policy configuration
    â”‚
    â–¼
[Create Interpretation Prompt]
    â”‚
    â”œâ”€â–º System: "Traffic engineering analyst"
    â””â”€â–º User: Formatted prompt with data
    â”‚
    â–¼
[Call Groq API]
    â”‚
    â”œâ”€â–º Model: llama-3.3-70b-versatile
    â”œâ”€â–º Temperature: 0.5 (more focused)
    â””â”€â–º Max tokens: 1500
    â”‚
    â–¼
[Receive Natural Language Analysis]
    â”‚
    â”œâ”€â–º Performance summary
    â”œâ”€â–º Trade-off analysis
    â”œâ”€â–º Climate resilience assessment
    â””â”€â–º Recommendations
    â”‚
    â–¼
[Return Formatted Text]
```

### 5.6 Multi-Objective Optimizer Module

**File:** `modules/optimizer.py`

**Class:** `MultiObjectiveOptimizer`

**Purpose:** Perform Pareto frontier analysis and optimization

**Key Methods:**
```python
class MultiObjectiveOptimizer:
    def calculate_pareto_frontier(self, policies_metrics) -> list:
        """
        Identify Pareto optimal solutions
        
        Algorithm:
        1. For each policy i:
            2. Check if dominated by any other policy j
            3. Dominated if: all objectives worse or equal, 
                           and at least one strictly worse
            4. If not dominated â†’ Pareto optimal
        
        Returns: List of Pareto optimal policy names
        """
        
    def rank_policies_by_dominance(self, policies_metrics) -> dict:
        """
        Rank policies by dominance count
        
        Returns: {policy_name: rank}
        """
        
    def calculate_hypervolume(self, policies_metrics, 
                             reference_point=None) -> float:
        """Calculate hypervolume indicator for solution quality"""
        
    def calculate_weighted_score(self, metrics, weights=None) -> float:
        """Calculate weighted aggregate score"""
        
    def generate_optimization_report(self, policies_metrics) -> str:
        """Generate comprehensive optimization report"""
```

**Pareto Dominance Algorithm:**
```python
def _dominates(solution_a, solution_b):
    """
    Check if solution A dominates solution B
    
    Dominance conditions:
    - All objectives of A are â‰¤ B (for minimization)
    - At least one objective of A is < B
    
    Returns: True if A dominates B
    """
    all_better_or_equal = all(a <= b for a, b in zip(solution_a, solution_b))
    at_least_one_better = any(a < b for a, b in zip(solution_a, solution_b))
    
    return all_better_or_equal and at_least_one_better
```

**Objective Normalization:**

For consistent comparison, objectives are normalized:
- **Minimization objectives** (delay, emissions): Keep as-is (lower is better)
- **Maximization objectives** (throughput, speed): Negate (convert to minimization)

### 5.7 Statistical Analyzer Module

**File:** `modules/analytics.py`

**Class:** `StatisticalAnalyzer`

**Purpose:** Perform rigorous statistical analysis

**Key Methods:**
```python
class StatisticalAnalyzer:
    def perform_anova(self, results) -> dict:
        """
        Perform one-way ANOVA
        
        H0: All policies have equal mean performance
        H1: At least one policy differs
        
        Returns:
            {
                metric: {
                    'f_statistic': float,
                    'p_value': float,
                    'significant': bool,
                    'interpretation': str
                }
            }
        """
        
    def calculate_confidence_intervals(self, results, 
                                      confidence=0.95) -> dict:
        """
        Calculate 95% confidence intervals
        
        CI = mean Â± t(Î±/2, n-1) Ã— SE
        
        Returns:
            {
                policy: {
                    metric: {
                        'mean': float,
                        'lower': float,
                        'upper': float,
                        'margin_of_error': float
                    }
                }
            }
        """
        
    def calculate_correlation_matrix(self, results) -> pd.DataFrame:
        """Calculate Pearson correlation matrix"""
        
    def perform_sensitivity_analysis(self, base_metrics, 
                                     parameter_variations) -> pd.DataFrame:
        """Analyze parameter sensitivity"""
```

**ANOVA Implementation:**
```python
from scipy import stats

# Collect data for each policy
policy_data = [
    [metric_value for scenario in scenarios],
    # ... for each policy
]

# Perform one-way ANOVA
f_statistic, p_value = stats.f_oneway(*policy_data)

# Interpret
significant = p_value < 0.05  # Î± = 0.05
```

**Confidence Interval Calculation:**
```python
from scipy import stats
import numpy as np

mean = np.mean(values)
std_error = stats.sem(values)
degrees_of_freedom = len(values) - 1

# t-distribution critical value
t_critical = stats.t.ppf(1 - (1 - confidence) / 2, degrees_of_freedom)

# Confidence interval
margin_of_error = t_critical * std_error
lower_bound = mean - margin_of_error
upper_bound = mean + margin_of_error
```

### 5.8 Report Generator Module

**File:** `modules/report_generator.py`

**Class:** `ReportGenerator`

**Purpose:** Generate publication-ready reports

**Key Methods:**
```python
class ReportGenerator:
    def generate_markdown_report(self, results, policies, 
                                stats_report, optimization_report,
                                researcher, institution) -> str:
        """Generate comprehensive markdown report"""
        
    def create_visualization_figure(self, results, 
                                    chart_type) -> go.Figure:
        """Create chart for report inclusion"""
```

**Report Structure:**
```markdown
# TrafficGen-AI Analysis Report

## Executive Summary
- Overview of analysis
- Key highlights
- Main findings

## Policy Overview
- List of evaluated policies
- Configuration details

## Climate Scenario Analysis
- Scenarios tested
- Performance under stress

## Performance Metrics
- Detailed results table
- Metric comparisons

## Statistical Analysis
- ANOVA results
- Confidence intervals
- Correlations

## Multi-Objective Optimization
- Pareto frontier
- Rankings
- Trade-offs

## Visualizations
- Charts and graphs

## Key Findings
- Summary of results

## Recommendations
- Actionable insights

## Methodology
- Framework description
- Limitations

## Appendix
- Detailed configurations
```

### 5.9 Advanced Visualizations Module

**File:** `modules/advanced_visualizations.py`

**Class:** `AdvancedVisualizer`

**Purpose:** Create premium interactive visualizations

**Key Methods:**
```python
class AdvancedVisualizer:
    def create_3d_performance_surface(self, results) -> go.Figure:
        """3D surface plot of performance"""
        
    def create_parallel_coordinates(self, results) -> go.Figure:
        """Parallel coordinates for multi-metric comparison"""
        
    def create_sankey_diagram(self, results) -> go.Figure:
        """Flow diagram showing relationships"""
        
    def create_sunburst_chart(self, results) -> go.Figure:
        """Hierarchical sunburst visualization"""
        
    def create_treemap(self, results) -> go.Figure:
        """Treemap for performance hierarchy"""
        
    def create_violin_plot(self, results, metric) -> go.Figure:
        """Distribution analysis with violin plots"""
```

**Visualization Technologies:**

1. **3D Surface Plots**
   - Technology: Plotly `go.Surface`
   - Use case: Visualize performance across policy Ã— scenario space

2. **Parallel Coordinates**
   - Technology: Plotly `go.Parcoords`
   - Use case: Compare multiple metrics simultaneously

3. **Sankey Diagrams**
   - Technology: Plotly `go.Sankey`
   - Use case: Show flow from policies â†’ scenarios â†’ outcomes

4. **Sunburst Charts**
   - Technology: Plotly `go.Sunburst`
   - Use case: Hierarchical performance relationships

5. **Treemaps**
   - Technology: Plotly `go.Treemap`
   - Use case: Performance hierarchy visualization

6. **Violin Plots**
   - Technology: Plotly `go.Violin`
   - Use case: Distribution analysis and outlier detection

---

## 6. API Integration

### 6.1 Groq API Integration

**Endpoint:** `https://api.anthropic.com/v1/messages`

**Authentication:**
```python
from groq import Groq

client = Groq(api_key=GROQ_API_KEY)
```

**Request Format:**
```python
response = client.chat.completions.create(
    model="llama-3.3-70b-versatile",
    messages=[
        {
            "role": "system",
            "content": "System prompt defining behavior"
        },
        {
            "role": "user",
            "content": "User prompt with context"
        }
    ],
    temperature=0.7,        # Creativity level (0.0 - 1.0)
    max_tokens=2000,        # Maximum response length
)
```

**Response Handling:**
```python
# Extract content
response_text = response.choices[0].message.content.strip()

# Remove markdown artifacts
if response_text.startswith("```json"):
    response_text = response_text.replace("```json", "").replace("```", "").strip()

# Parse JSON
policy_config = json.loads(response_text)
```

**Error Handling:**
```python
try:
    response = client.chat.completions.create(...)
    
except json.JSONDecodeError as e:
    # Handle JSON parsing errors
    raise ValueError(f"Invalid JSON: {e}")
    
except Exception as e:
    # Handle API errors
    raise Exception(f"API Error: {e}")
```

**Rate Limiting:**
- Current implementation: No explicit rate limiting
- Production recommendation: Implement exponential backoff
- Suggested library: `tenacity` for retry logic

### 6.2 SUMO API Integration (Future)

**Current Status:** Synthetic data generation

**Planned Integration:**
```python
import traci

# Start SUMO
traci.start([
    "sumo",
    "-c", config_file,
    "--step-length", str(SIMULATION_STEP_SIZE)
])

# Simulation loop
while traci.simulation.getMinExpectedNumber() > 0:
    traci.simulationStep()
    
    # Collect data
    for vehicle_id in traci.vehicle.getIDList():
        delay = traci.vehicle.getAccumulatedWaitingTime(vehicle_id)
        speed = traci.vehicle.getSpeed(vehicle_id)
        # ... collect more data

# Close SUMO
traci.close()
```

---

## 7. Algorithm Implementations

### 7.1 Pareto Frontier Algorithm

**Complexity:** O(nÂ²m) where n = policies, m = objectives
```python
def calculate_pareto_frontier(policies_metrics):
    """
    Input: {policy_name: {metric: value}}
    Output: [pareto_optimal_policy_names]
    """
    policy_names = list(policies_metrics.keys())
    n_policies = len(policy_names)
    
    # Convert to objective matrix
    objective_matrix = []
    for policy_name in policy_names:
        metrics = policies_metrics[policy_name]
        obj_values = [
            metrics['average_delay'],      # Minimize
            -metrics['throughput'],        # Maximize â†’ negate
            metrics['co2_emissions'],      # Minimize
            -metrics['average_speed']      # Maximize â†’ negate
        ]
        objective_matrix.append(obj_values)
    
    objective_matrix = np.array(objective_matrix)
    
    # Find non-dominated solutions
    pareto_front = []
    
    for i in range(n_policies):
        is_dominated = False
        
        for j in range(n_policies):
            if i != j:
                # Check if i is dominated by j
                if dominates(objective_matrix[j], objective_matrix[i]):
                    is_dominated = True
                    break
        
        if not is_dominated:
            pareto_front.append(policy_names[i])
    
    return pareto_front

def dominates(solution_a, solution_b):
    """Check if solution A dominates solution B"""
    # All objectives better or equal
    all_better_or_equal = np.all(solution_a <= solution_b)
    
    # At least one strictly better
    at_least_one_better = np.any(solution_a < solution_b)
    
    return all_better_or_equal and at_least_one_better
```

### 7.2 ANOVA Implementation

**Test:** One-way ANOVA (Analysis of Variance)

**Hypotheses:**
- Hâ‚€: Î¼â‚ = Î¼â‚‚ = ... = Î¼â‚– (all policies have equal means)
- Hâ‚: At least one policy mean differs

**Formula:**

F = MSB / MSW

where:
- MSB = Mean Square Between groups
- MSW = Mean Square Within groups

**Implementation:**
```python
from scipy import stats

def perform_anova(results):
    """
    Perform one-way ANOVA for each metric
    """
    anova_results = {}
    
    metrics_list = ['average_delay', 'throughput', 'co2_emissions', 'average_speed']
    
    for metric in metrics_list:
        # Collect data for each policy
        policy_data = []
        
        for policy_name, scenarios in results.items():
            values = [
                scenario_data['metrics'][metric]
                for scenario_data in scenarios.values()
            ]
            policy_data.append(values)
        
        # Perform ANOVA
        f_statistic, p_value = stats.f_oneway(*policy_data)
        
        # Interpret
        significant = p_value < 0.05
        
        if p_value < 0.001:
            interpretation = "Highly significant (p < 0.001)"
        elif p_value < 0.01:
            interpretation = "Very significant (p < 0.01)"
        elif p_value < 0.05:
            interpretation = "Significant (p < 0.05)"
        else:
            interpretation = "Not significant (p â‰¥ 0.05)"
        
        anova_results[metric] = {
            'f_statistic': f_statistic,
            'p_value': p_value,
            'significant': significant,
            'interpretation': interpretation
        }
    
    return anova_results
```

### 7.3 Confidence Interval Calculation

**Formula:**

CI = xÌ„ Â± t(Î±/2, n-1) Ã— SE

where:
- xÌ„ = sample mean
- t = t-distribution critical value
- SE = standard error = s / âˆšn
- Î± = significance level (0.05 for 95% CI)
- n = sample size

**Implementation:**
```python
from scipy import stats
import numpy as np

def calculate_confidence_intervals(results, confidence=0.95):
    """
    Calculate confidence intervals for each policy-metric combination
    """
    ci_results = {}
    
    for policy_name, scenarios in results.items():
        ci_results[policy_name] = {}
        
        # Collect metrics across scenarios
        metrics_data = {}
        for scenario_name, data in scenarios.items():
            for metric, value in data['metrics'].items():
                if metric not in metrics_data:
                    metrics_data[metric] = []
                metrics_data[metric].append(value)
        
        # Calculate CI for each metric
        for metric, values in metrics_data.items():
            if len(values) > 1:
                mean = np.mean(values)
                std_error = stats.sem(values)  # Standard error
                df = len(values) - 1           # Degrees of freedom
                
                # t-critical value
                t_critical = stats.t.ppf((1 + confidence) / 2, df)
                
                # Margin of error
                margin_of_error = t_critical * std_error
                
                # Confidence interval
                ci_lower = mean - margin_of_error
                ci_upper = mean + margin_of_error
                
                ci_results[policy_name][metric] = {
                    'mean': mean,
                    'lower': ci_lower,
                    'upper': ci_upper,
                    'margin_of_error': margin_of_error
                }
    
    return ci_results
```

### 7.4 Composite Score Calculation

**Purpose:** Aggregate multiple objectives into single performance score

**Normalization:**

Each metric is normalized to 0-100 scale:
```python
def normalize_metric(value, metric_type):
    """
    Normalize metric to 0-100 scale
    100 = best, 0 = worst
    """
    if metric_type == 'average_delay':
        # 0-300 seconds range
        # Lower is better
        return max(0, min(100, (300 - value) / 300 * 100))
    
    elif metric_type == 'throughput':
        # 0-2000 veh/hour range
        # Higher is better
        return max(0, min(100, value / 2000 * 100))
    
    elif metric_type == 'co2_emissions':
        # 0-1000 kg range
        # Lower is better
        return max(0, min(100, (1000 - value) / 1000 * 100))
    
    elif metric_type == 'average_speed':
        # 0-60 km/h range
        # Higher is better
        return max(0, min(100, value / 60 * 100))
    
    else:
        return 50  # Default
```

**Weighted Aggregation:**
```python
def calculate_composite_score(metrics, weights=None):
    """
    Calculate weighted composite score
    
    Default weights: Equal for all metrics (0.25 each)
    """
    if weights is None:
        weights = {
            'average_delay': 0.25,
            'throughput': 0.25,
            'co2_emissions': 0.25,
            'average_speed': 0.25
        }
    
    score = 0.0
    
    for metric, value in metrics.items():
        normalized = normalize_metric(value, metric)
        weight = weights.get(metric, 0)
        score += normalized * weight
    
    return round(score, 2)
```

---

## 8. Database Schema

### 8.1 Current Implementation: Session State

**Storage Method:** Streamlit session state (in-memory)

**Structure:**
```python
st.session_state = {
    # Generated policies list
    'generated_policies': [
        {
            'policy_name': str,
            'policy_type': str,
            'description': str,
            'parameters': dict,
            'expected_impacts': dict,
            'implementation_notes': str,
            'generation_metadata': {
                'network_type': str,
                'climate_scenario': str,
                'policy_objective': str,
                'constraints': str,
                'model_used': str,
                'timestamp': str
            },
            'generated_at': str  # ISO datetime
        },
        # ... more policies
    ],
    
    # Simulation results
    'simulation_results': {
        'policy_name_1': {
            'scenario_name_1': {
                'metrics': {
                    'average_delay': float,
                    'throughput': float,
                    'co2_emissions': float,
                    'average_speed': float,
                    'total_travel_time': float
                },
                'policy_config': dict,
                'scenario': dict
            },
            # ... more scenarios
        },
        # ... more policies
    },
    
    # Optimization results
    'pareto_front': [
        'policy_name_1',
        'policy_name_2',
        # ... pareto optimal policies
    ],
    
    # Statistical analysis results
    'statistical_analysis': {
        'anova': {
            'metric_name': {
                'f_statistic': float,
                'p_value': float,
                'significant': bool,
                'interpretation': str
            },
            # ... more metrics
        },
        # ... more analyses
    },
    
    # UI state
    'api_key_set': bool,
    'theme': str,  # 'light' or 'dark'
}
```

**Limitations:**
- Data lost when session ends
- No persistence across sessions
- Limited to single user
- No historical tracking

### 8.2 Future Database Schema (PostgreSQL/SQLite)

**Proposed Tables:**
```sql
-- Users table
CREATE TABLE users (
    user_id SERIAL PRIMARY KEY,
    username VARCHAR(100) UNIQUE NOT NULL,
    email VARCHAR(255) UNIQUE NOT NULL,
    institution VARCHAR(255),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Policies table
CREATE TABLE policies (
    policy_id SERIAL PRIMARY KEY,
    user_id INTEGER REFERENCES users(user_id),
    policy_name VARCHAR(255) NOT NULL,
    policy_type VARCHAR(100),
    description TEXT,
    parameters JSONB,
    expected_impacts JSONB,
    implementation_notes TEXT,
    generation_metadata JSONB,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Simulations table
CREATE TABLE simulations (
    simulation_id SERIAL PRIMARY KEY,
    policy_id INTEGER REFERENCES policies(policy_id),
    climate_scenario VARCHAR(50),
    simulation_time INTEGER,
    num_vehicles INTEGER,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Simulation results table
CREATE TABLE simulation_results (
    result_id SERIAL PRIMARY KEY,
    simulation_id INTEGER REFERENCES simulations(simulation_id),
    average_delay FLOAT,
    throughput FLOAT,
    co2_emissions FLOAT,
    average_speed FLOAT,
    total_travel_time FLOAT,
    composite_score FLOAT,
    raw_data JSONB
);

-- Optimization results table
CREATE TABLE optimization_results (
    optimization_id SERIAL PRIMARY KEY,
    simulation_id INTEGER REFERENCES simulations(simulation_id),
    is_pareto_optimal BOOLEAN,
    dominance_rank INTEGER,
    hypervolume FLOAT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Statistical analyses table
CREATE TABLE statistical_analyses (
    analysis_id SERIAL PRIMARY KEY,
    simulation_id INTEGER REFERENCES simulations(simulation_id),
    analysis_type VARCHAR(50),  -- 'ANOVA', 'CI', 'Correlation'
    metric_name VARCHAR(100),
    results JSONB,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Reports table
CREATE TABLE reports (
    report_id SERIAL PRIMARY KEY,
    user_id INTEGER REFERENCES users(user_id),
    report_type VARCHAR(50),
    title VARCHAR(255),
    content TEXT,
    metadata JSONB,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

---

## 9. Security & Privacy

### 9.1 API Key Management

**Storage:**
```
.env file (local, not committed to Git)
Environment variables (production)
```

**Best Practices:**
- Never commit `.env` to version control
- Use `.gitignore` to exclude sensitive files
- Rotate API keys periodically
- Use separate keys for development/production

**Access Control:**
```python
# Only load from environment
GROQ_API_KEY = os.getenv("GROQ_API_KEY", "")

# Never log or display
if not GROQ_API_KEY:
    st.error("API key not configured")
    # Don't show the key value
```

### 9.2 Data Privacy

**Current Implementation:**
- All data stored in session state (temporary)
- No data persistence beyond session
- No user authentication
- No data collection or tracking

**Recommendations for Production:**
- Implement user authentication (OAuth, JWT)
- Encrypt sensitive data at rest
- Use HTTPS for all communications
- Implement role-based access control (RBAC)
- Add data retention policies
- Comply with GDPR/privacy regulations

### 9.3 Input Validation

**Policy Configuration:**
```python
def validate_policy(policy):
    """Validate policy structure"""
    required_fields = [
        "policy_name",
        "policy_type",
        "description",
        "parameters"
    ]
    
    for field in required_fields:
        if field not in policy:
            return False, f"Missing: {field}"
    
    if not isinstance(policy["parameters"], dict):
        return False, "Invalid parameters"
    
    return True, "Valid"
```

**User Input Sanitization:**
- Validate network types against allowed list
- Check climate scenarios against predefined set
- Sanitize text inputs (constraints, descriptions)
- Limit input lengths
- Prevent injection attacks

---

## 10. Performance Optimization

### 10.1 Caching Strategy

**Streamlit Caching:**
```python
@st.cache_data
def load_climate_scenarios():
    """Cache climate scenario data"""
    return CLIMATE_SCENARIOS

@st.cache_resource
def initialize_simulator():
    """Cache simulator initialization"""
    return SUMOSimulator()
```

**Benefits:**
- Faster page loads
- Reduced API calls
- Better user experience

### 10.2 Computational Optimization

**Vectorization:**
```python
# Instead of loops
delays = [vehicle['delay'] for vehicle in vehicles]
average_delay = sum(delays) / len(delays)

# Use numpy
import numpy as np
delays = np.array([v['delay'] for v in vehicles])
average_delay = np.mean(delays)
```

**Parallel Processing (Future):**
```python
from concurrent.futures import ThreadPoolExecutor

def run_simulation_parallel(policy_scenario_pairs):
    """Run multiple simulations in parallel"""
    with ThreadPoolExecutor(max_workers=4) as executor:
        results = executor.map(run_single_simulation, policy_scenario_pairs)
    return list(results)
```

### 10.3 Memory Management

**Large Dataset Handling:**
```python
# Process in chunks
chunk_size = 1000
for i in range(0, len(vehicles), chunk_size):
    chunk = vehicles[i:i+chunk_size]
    process_chunk(chunk)
```

**Garbage Collection:**
```python
import gc

# After large operations
del large_dataframe
gc.collect()
```

---

## 11. Deployment Architecture

### 11.1 Local Deployment

**Current Setup:**
```
User's Machine
    â”‚
    â”œâ”€â–º Python Environment (venv)
    â”‚   â”œâ”€â–º Streamlit
    â”‚   â”œâ”€â–º Groq Client
    â”‚   â””â”€â–º Other dependencies
    â”‚
    â”œâ”€â–º Application Files
    â”‚   â”œâ”€â–º app.py
    â”‚   â”œâ”€â–º modules/
    â”‚   â”œâ”€â–º config/
    â”‚   â””â”€â–º .env
    â”‚
    â””â”€â–º Browser (localhost:8501)
```

**Command:**
```bash
streamlit run app.py
```

### 11.2 Cloud Deployment (Future)

**Streamlit Cloud:**
```
GitHub Repository
    â”‚
    â–¼
Streamlit Cloud
    â”‚
    â”œâ”€â–º Auto-deployment from GitHub
    â”œâ”€â–º Secrets management
    â”œâ”€â–º SSL/HTTPS enabled
    â””â”€â–º Public URL
```

**Requirements:**
```
# requirements.txt
streamlit==1.31.0
groq==0.4.2
# ... other dependencies
```

**Configuration:**
```toml
# .streamlit/config.toml
[server]
headless = true
port = 8501
enableCORS = false

[theme]
primaryColor = "#667eea"
backgroundColor = "#ffffff"
secondaryBackgroundColor = "#f0f2f6"
```

**Secrets:**
```toml
# .streamlit/secrets.toml (not committed)
GROQ_API_KEY = "your_api_key"
```

### 11.3 Production Architecture (Enterprise)
```
                    Internet
                        â”‚
                        â–¼
                [Load Balancer]
                        â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼               â–¼               â–¼
   [App Server 1] [App Server 2] [App Server 3]
        â”‚               â”‚               â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â–¼           â–¼           â–¼
        [Redis]   [PostgreSQL]  [Object Storage]
         Cache      Database      (S3/Azure)
```

**Components:**
- **Load Balancer:** Nginx/AWS ALB
- **App Servers:** Docker containers with Streamlit
- **Database:** PostgreSQL for persistence
- **Cache:** Redis for session/result caching
- **Storage:** S3/Azure for reports and large files
- **Monitoring:** Prometheus + Grafana
- **Logging:** ELK Stack (Elasticsearch, Logstash, Kibana)

---

## 12. Future Extensions

### 12.1 Real SUMO Integration

**Implementation Plan:**

1. **Network Import:**
```python
   def import_osm_network(osm_file):
       """Import OpenStreetMap network"""
       subprocess.run([
           'netconvert',
           '--osm-files', osm_file,
           '--output-file', 'network.net.xml'
       ])
```

2. **TraCI Integration:**
```python
   import traci
   
   traci.start(['sumo', '-c', 'config.sumocfg'])
   
   while traci.simulation.getMinExpectedNumber() > 0:
       traci.simulationStep()
       collect_vehicle_data()
   
   traci.close()
```

### 12.2 Machine Learning Integration

**Planned Features:**

1. **Demand Prediction:**
```python
   from sklearn.ensemble import RandomForestRegressor
   
   model = RandomForestRegressor()
   model.fit(historical_data, traffic_demand)
   predicted_demand = model.predict(future_conditions)
```

2. **Policy Performance Prediction:**
```python
   # Train on simulation results
   # Predict performance without full simulation
```

### 12.3 Real-Time Data Integration

**Data Sources:**
- Traffic APIs (Google Maps, HERE, TomTom)
- Weather APIs
- Public transit feeds (GTFS Real-time)
- IoT sensors
- Traffic cameras

**Implementation:**
```python
import requests

def get_real_time_traffic(location):
    response = requests.get(
        f'https://api.traffic.com/v1/flow',
        params={'location': location},
        headers={'API-Key': API_KEY}
    )
    return response.json()
```

### 12.4 Collaborative Features

**Planned:**
- Multi-user support
- Shared workspaces
- Comment system
- Version control for policies
- Approval workflows

### 12.5 Mobile Application

**React Native App:**
- View simulation results
- Monitor running simulations
- Receive notifications
- Quick policy comparisons
- Offline report viewing

---

## ðŸ“š References

### Academic Papers
1. Krajzewicz et al. (2012) - SUMO: Simulation of Urban MObility
2. Deb et al. (2002) - Multi-objective Optimization using NSGA-II
3. Box & Anderson (1955) - Design and Analysis of Factorial Experiments

### Technical Documentation
- [Streamlit Docs](https://docs.streamlit.io/)
- [SUMO Documentation](https://sumo.dlr.de/docs/)
- [Plotly Python](https://plotly.com/python/)
- [SciPy Statistical Functions](https://docs.scipy.org/doc/scipy/reference/stats.html)

### API Documentation
- [Groq API Reference](https://console.groq.com/docs)

---

## ðŸ“ Version History

| Version | Date | Changes |
|---------|------|---------|
| 2.0 | 2025-12-28 | Ultimate Edition with all advanced features |
| 1.0 | 2025-12-15 | Initial release with basic features |

---

## ðŸ‘¨â€ðŸ’» Author

**Mahbub Hassan**  
Transportation Engineering Researcher  
Chulalongkorn University, Bangkok, Thailand  
Email: mahbub.hassan@ieee.org

---

**Â© 2025 TrafficGen-AI Ultimate Edition - All Rights Reserved**